{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('evonikAML': conda)",
   "metadata": {
    "interpreter": {
     "hash": "23181a1f8d092a550afd91e2df594161a080a135fdd639e3f5e4e05e6251c17d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Datastore, Dataset, Experiment, Environment"
   ]
  },
  {
   "source": [
    "# Connnect to the AML Workspace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "#connect to the workspace\n",
    "ws = Workspace.from_config(\".azure\")\n",
    "\n",
    "# get the compute target\n",
    "compute_target = ws.compute_targets[\"cpu-cluster\"]\n",
    "\n",
    "# get the default datastore\n",
    "datastore = ws.get_default_datastore()"
   ]
  },
  {
   "source": [
    "# Import the training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_ds = Dataset.get_by_name(ws, \"diabetes_cleaned\")\n",
    "diabetes_df = diabetes_ds.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age            class\n",
       "0     6   148    72    35     0  33.6  0.627   50  tested_positive\n",
       "1     1    85    66    29     0  26.6  0.351   31  tested_negative\n",
       "2     8   183    64     0     0  23.3  0.672   32  tested_positive\n",
       "3     1    89    66    23    94  28.1  0.167   21  tested_negative\n",
       "4     0   137    40    35   168  43.1  2.288   33  tested_positive"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preg</th>\n      <th>plas</th>\n      <th>pres</th>\n      <th>skin</th>\n      <th>insu</th>\n      <th>mass</th>\n      <th>pedi</th>\n      <th>age</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>tested_positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>tested_negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>tested_positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>tested_negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>tested_positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "diabetes_df.head()"
   ]
  },
  {
   "source": [
    "# Train a Model with python"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Train DecisionTreeClassifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting src/train_DTC.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/train_DTC.py\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from azureml.core import Workspace, Datastore, Dataset, Run\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "from azureml.core.model import Model\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import sklearn\n",
    "\n",
    "# get the current run\n",
    "run = Run.get_context()\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "# get the dataset\n",
    "ds = Dataset.get_by_name(ws, \"diabetes_cleaned\")\n",
    "diabetes_df = ds.to_pandas_dataframe()\n",
    "\n",
    "\n",
    "X = diabetes_df.drop(\"class\", axis=1)\n",
    "y = diabetes_df[\"class\"]\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = diabetes_df[\"class\"], random_state=0)\n",
    "\n",
    "# init the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get the predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# register a sample_input\n",
    "sample_input = diabetes_df[:1].drop(\"class\", axis=1)\n",
    "sample_input = Dataset.Tabular.register_pandas_dataframe(name=\"diabetes_sample_input\",target=datastore, dataframe=sample_input)\n",
    "\n",
    "# register a sample_output\n",
    "sample_output = pd.DataFrame({\"class\": y_pred[:1]})\n",
    "sample_output = Dataset.Tabular.register_pandas_dataframe(name=\"diabetes_sample_output\",target=datastore, dataframe=sample_output)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "# log the accuracy to the Run\n",
    "run.log(\"acc\", acc)\n",
    "\n",
    "# log confusion matrix\n",
    "cmtx = sklearn.metrics.confusion_matrix(y_test,(y_pred))\n",
    "\n",
    "cmtx_wrapper =  {\n",
    "       \"schema_type\": \"confusion_matrix\",\n",
    "       \"schema_version\": \"v1\",\n",
    "       \"data\": {\n",
    "           \"class_labels\": diabetes_df[\"class\"].unique().tolist(),\n",
    "           \"matrix\": cmtx.tolist()\n",
    "       }\n",
    "   }\n",
    "   \n",
    "run.log_confusion_matrix(\"confusion matrix\", cmtx_wrapper, description='')\n",
    "\n",
    "# save the model to disk\n",
    "joblib.dump(model, 'model.pkl')\n",
    "\n",
    "# register the model in the workspace\n",
    "model_reg = Model.register(model_path=\"model.pkl\",\n",
    "                       model_name=\"sklearn-model\",\n",
    "                       model_framework=Model.Framework.SCIKITLEARN,\n",
    "                       model_framework_version=sklearn.__version__,\n",
    "                       sample_input_dataset=sample_input,\n",
    "                       sample_output_dataset=sample_output,\n",
    "                       tags={'area': \"diabetes\", 'type': \"classification\"},\n",
    "                       resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5),\n",
    "                       description=\"DecisionTreeClassifier for diabetes dataset\",\n",
    "                       workspace=ws)"
   ]
  },
  {
   "source": [
    "## Define the Run Configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.core.environment import CondaDependencies\n",
    "\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# create a new runconfig object\n",
    "run_config = RunConfiguration()\n",
    "\n",
    "# # enable Docker \n",
    "run_config.environment.docker.enabled = True\n",
    "\n",
    "# # set Docker base image to the default CPU-based image\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "\n",
    "# # # use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "run_config.environment.python.user_managed_dependencies = True\n",
    "\n",
    "# # specify CondaDependencies obj\n",
    "run_config.environment = Environment.from_conda_specification(name = \"train-env\", file_path = \"environment.yml\")\n"
   ]
  },
  {
   "source": [
    "## Create the Python script step"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_DTC = PythonScriptStep(\n",
    "    script_name=\"train_DTC.py\",\n",
    "    source_directory=\"src\",\n",
    "    compute_target=\"cpu-cluster\",\n",
    "    runconfig=run_config)\n",
    "\n",
    "model_train_pipe = Pipeline(workspace=ws, steps=[train_DTC])"
   ]
  },
  {
   "source": [
    "## Validate the Pipeline Configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Step train_DTC.py is ready to be created [6837fb8d]\nPipeline validation complete\n"
     ]
    }
   ],
   "source": [
    "model_train_pipe.validate()\n",
    "print(\"Pipeline validation complete\")"
   ]
  },
  {
   "source": [
    "## Run the Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created step train_DTC.py [6837fb8d][b03d5904-f257-48bd-9ad4-2b48e95e29d8], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 67984c12-e3ab-4e6a-a28a-4247949af128\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/training/runs/67984c12-e3ab-4e6a-a28a-4247949af128?wsid=/subscriptions/3a0172d3-ec0d-46bb-a88a-ff41a302711a/resourcegroups/Evonik/workspaces/AMLWorkspace\n",
      "PipelineRunId: 67984c12-e3ab-4e6a-a28a-4247949af128\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/training/runs/67984c12-e3ab-4e6a-a28a-4247949af128?wsid=/subscriptions/3a0172d3-ec0d-46bb-a88a-ff41a302711a/resourcegroups/Evonik/workspaces/AMLWorkspace\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '67984c12-e3ab-4e6a-a28a-4247949af128', 'status': 'Completed', 'startTimeUtc': '2021-02-08T19:00:10.548246Z', 'endTimeUtc': '2021-02-08T19:08:13.883574Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlstorageacc.blob.core.windows.net/azureml/ExperimentRun/dcid.67984c12-e3ab-4e6a-a28a-4247949af128/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=qdC2dyC7hjDHR5PU2xZkrKl7h9v%2FOqA%2FacZTHM19A48%3D&st=2021-02-08T18%3A58%3A55Z&se=2021-02-09T03%3A08%3A55Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlstorageacc.blob.core.windows.net/azureml/ExperimentRun/dcid.67984c12-e3ab-4e6a-a28a-4247949af128/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=jzztCQHgxITOyZCy5wX6p%2F6gudA8DdVopaXL3nsBAD8%3D&st=2021-02-08T18%3A58%3A55Z&se=2021-02-09T03%3A08%3A55Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlstorageacc.blob.core.windows.net/azureml/ExperimentRun/dcid.67984c12-e3ab-4e6a-a28a-4247949af128/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=0lrXGtY6ZEJ5nf%2FxqMn%2FYoLPwMgs%2F4X4vJWaSb%2FTSys%3D&st=2021-02-08T18%3A58%3A55Z&se=2021-02-09T03%3A08%3A55Z&sp=r'}, 'submittedBy': 'Bjarne Meyn'}\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "pipeline_run = Experiment(ws, 'training').submit(model_train_pipe)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "source": [
    "********"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Train Multiple Models in the Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Define the steps"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "train_DTC = PythonScriptStep(\n",
    "    script_name=\"train_DTC.py\",\n",
    "    source_directory=\"src\",\n",
    "    compute_target=\"cpu-cluster\",\n",
    "    runconfig=run_config)\n",
    "\n",
    "# KNeighborsClassifier\n",
    "train_KNC = PythonScriptStep(\n",
    "    script_name=\"train_KNC.py\",\n",
    "    source_directory=\"src\",\n",
    "    compute_target=\"cpu-cluster\",\n",
    "    runconfig=run_config)\n",
    "\n",
    "# RandomForestClassifier\n",
    "train_RFC = PythonScriptStep(\n",
    "    script_name=\"train_RFC.py\",\n",
    "    source_directory=\"src\",\n",
    "    compute_target=\"cpu-cluster\",\n",
    "    runconfig=run_config)\n",
    "\n",
    "\n",
    "multi_model_train_pipe = Pipeline(workspace=ws, steps=[train_DTC, train_KNC, train_RFC])"
   ]
  },
  {
   "source": [
    "## Run the Pipelines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created step train_DTC.py [3ad555df][b03d5904-f257-48bd-9ad4-2b48e95e29d8], (This step is eligible to reuse a previous run's output)\n",
      "Created step train_KNC.py [34cee30b][07c2a78b-8a81-4f94-9b5e-0bb505dea832], (This step will run and generate new outputs)\n",
      "Created step train_RFC.py [6a2fac9d][4fd73541-dc02-43f5-a922-86ea561f4ede], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 3058143a-7e0e-4fb6-a1c8-9714fd395ff6\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/training/runs/3058143a-7e0e-4fb6-a1c8-9714fd395ff6?wsid=/subscriptions/3a0172d3-ec0d-46bb-a88a-ff41a302711a/resourcegroups/Evonik/workspaces/AMLWorkspace\n",
      "PipelineRunId: 3058143a-7e0e-4fb6-a1c8-9714fd395ff6\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/training/runs/3058143a-7e0e-4fb6-a1c8-9714fd395ff6?wsid=/subscriptions/3a0172d3-ec0d-46bb-a88a-ff41a302711a/resourcegroups/Evonik/workspaces/AMLWorkspace\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n",
      "\n",
      "\n",
      "\n",
      "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n",
      "\n",
      "\n",
      "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '3058143a-7e0e-4fb6-a1c8-9714fd395ff6', 'status': 'Completed', 'startTimeUtc': '2021-02-08T19:09:12.929715Z', 'endTimeUtc': '2021-02-08T19:12:28.082927Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlstorageacc.blob.core.windows.net/azureml/ExperimentRun/dcid.3058143a-7e0e-4fb6-a1c8-9714fd395ff6/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=VTWV6X1DZSByktoev0AwZT9BKdaiKCBgBoEr%2FhMfvkQ%3D&st=2021-02-08T19%3A02%3A30Z&se=2021-02-09T03%3A12%3A30Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlstorageacc.blob.core.windows.net/azureml/ExperimentRun/dcid.3058143a-7e0e-4fb6-a1c8-9714fd395ff6/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=eZZhlGgNzR3A%2BT%2B9jtv5ryFqGBQwsBtPdvAIlHn%2BMaE%3D&st=2021-02-08T19%3A02%3A30Z&se=2021-02-09T03%3A12%3A30Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlstorageacc.blob.core.windows.net/azureml/ExperimentRun/dcid.3058143a-7e0e-4fb6-a1c8-9714fd395ff6/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=DfOOTvBpyiAp0U7w%2FFy%2FgToBD0V%2BC2j9uRfjjkQnJ1Q%3D&st=2021-02-08T19%3A02%3A30Z&se=2021-02-09T03%3A12%3A30Z&sp=r'}, 'submittedBy': 'Bjarne Meyn'}\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "pipeline_run = Experiment(ws, 'training').submit(multi_model_train_pipe)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}