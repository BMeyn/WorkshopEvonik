{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('evonikAML': conda)",
   "metadata": {
    "interpreter": {
     "hash": "23181a1f8d092a550afd91e2df594161a080a135fdd639e3f5e4e05e6251c17d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Create a new Dataset version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this Notebook we will create a new dataset in the AML Workspace. For this we will use the *diabetes* dataset witch you can donwload from the following URL\n",
    "\n",
    "- https://datahub.io/machine-learning/diabetes/r/diabetes.csv\n",
    "\n",
    "Download the Dataset an place it into a datafolder in your Workspace. You can load an display the data wiht the python pandas package\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age            class\n",
       "0     6   148    72    35     0  33.6  0.627   50  tested_positive\n",
       "1     1    85    66    29     0  26.6  0.351   31  tested_negative\n",
       "2     8   183    64     0     0  23.3  0.672   32  tested_positive\n",
       "3     1    89    66    23    94  28.1  0.167   21  tested_negative\n",
       "4     0   137    40    35   168  43.1  2.288   33  tested_positive"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preg</th>\n      <th>plas</th>\n      <th>pres</th>\n      <th>skin</th>\n      <th>insu</th>\n      <th>mass</th>\n      <th>pedi</th>\n      <th>age</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>tested_positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>tested_negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>tested_positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>tested_negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>tested_positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load an display the diabetes dataframe\n",
    "data = pd.read_csv(\"data/diabetes_csv.csv\")\n",
    "data.head()"
   ]
  },
  {
   "source": [
    "# 1. Create a Dataset with python"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Connect to the AML Workspace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Datastore, Dataset, Environment\n",
    "\n",
    "# connect to the workspace with config\n",
    "# interactive_auth = InteractiveLoginAuthentication(tenant_id=\"tenant-id\")\n",
    "ws = Workspace.from_config(\".azure\")\n",
    "\n",
    "# connect to the workspace with credentials\n",
    "# ws = Workspace.get(name=\"myworkspace\",\n",
    "#                    subscription_id='<azure-subscription-id>',\n",
    "#                    resource_group='myresourcegroup')\n"
   ]
  },
  {
   "source": [
    "## Get the default datastore and compute target"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "compute_target = ws.compute_targets[\"cpu-cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading data\\diabetes_csv.csv\n",
      "Uploaded data\\diabetes_csv.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_2b8124e0c1464737a4a215857bcba85e"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "datastore.upload(src_dir=\"data\", target_path='raw/diabetes.csv')"
   ]
  },
  {
   "source": [
    "## Create a Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_paths = [(datastore, 'raw/diabetes.csv')]\n",
    "\n",
    "diabetes_ds = Dataset.Tabular.from_delimited_files(path=datastore_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'raw/diabetes.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ]\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "diabetes_ds"
   ]
  },
  {
   "source": [
    "## Convert the dataset to a pandas dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age            class\n",
       "0     6   148    72    35     0  33.6  0.627   50  tested_positive\n",
       "1     1    85    66    29     0  26.6  0.351   31  tested_negative\n",
       "2     8   183    64     0     0  23.3  0.672   32  tested_positive\n",
       "3     1    89    66    23    94  28.1  0.167   21  tested_negative\n",
       "4     0   137    40    35   168  43.1  2.288   33  tested_positive"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preg</th>\n      <th>plas</th>\n      <th>pres</th>\n      <th>skin</th>\n      <th>insu</th>\n      <th>mass</th>\n      <th>pedi</th>\n      <th>age</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>tested_positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>tested_negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>tested_positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>tested_negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>tested_positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "diabetes_df = diabetes_ds.to_pandas_dataframe()\n",
    "diabetes_df.head()"
   ]
  },
  {
   "source": [
    "## Register the dataset to the AML Workspace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_ds = diabetes_ds.register(workspace=ws,name='diabetes',description='Diabetes training data', create_new_version=True)"
   ]
  },
  {
   "source": [
    "****"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 2. Define Pipeline to Update the Dataset frequently "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Define the Python execution script"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "With the IPython magic command *%%writefile* we can write the codecell into a python script"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting src/data_ingest.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/data_ingest.py\n",
    "\n",
    "from azureml.core import Run, Dataset\n",
    "\n",
    "# get the workspace from the current run\n",
    "run = Run.get_context()\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "\n",
    "# get the default datastore\n",
    "datastore = ws.get_default_datastore()\n",
    "# # create a TabularDataset\n",
    "datastore_paths = [(datastore,  'raw/diabetes.csv')]\n",
    "diabetes_ds = Dataset.Tabular.from_delimited_files(path=datastore_paths)\n",
    "# diabetes_df = diabetes_ds.to_pandas_dataframe()\n",
    "\n",
    "diabetes_ds = diabetes_ds.register(workspace=ws, name='diabetes',description='Diabetes training data', create_new_version=True)\n"
   ]
  },
  {
   "source": [
    "## Create a new Pipeline step"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "# create a pipeline step\n",
    "data_ingest_step = PythonScriptStep(\n",
    "    script_name=\"data_ingest.py\",\n",
    "    source_directory=\"src\",\n",
    "    # outputs = [diabetes_ds],\n",
    "    compute_target=compute_target,\n",
    "    allow_reuse=False)"
   ]
  },
  {
   "source": [
    "## Create and run the Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "# create the pipeline\n",
    "pipeline = Pipeline(workspace=ws, steps=[data_ingest_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created step data_ingest.py [62a2f86c][c179c6a5-8e1a-4a46-ad56-77c79ccdbc2b], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 1a5c0f11-a35f-43d3-a657-f478b03d8349\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/data_ingest/runs/1a5c0f11-a35f-43d3-a657-f478b03d8349?wsid=/subscriptions/3a0172d3-ec0d-46bb-a88a-ff41a302711a/resourcegroups/Evonik/workspaces/AMLWorkspace\n",
      "PipelineRunId: 1a5c0f11-a35f-43d3-a657-f478b03d8349\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/data_ingest/runs/1a5c0f11-a35f-43d3-a657-f478b03d8349?wsid=/subscriptions/3a0172d3-ec0d-46bb-a88a-ff41a302711a/resourcegroups/Evonik/workspaces/AMLWorkspace\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '1a5c0f11-a35f-43d3-a657-f478b03d8349', 'status': 'Completed', 'startTimeUtc': '2021-02-08T18:02:34.319606Z', 'endTimeUtc': '2021-02-08T18:09:03.621887Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlstorageacc.blob.core.windows.net/azureml/ExperimentRun/dcid.1a5c0f11-a35f-43d3-a657-f478b03d8349/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=tm4OifnrvTEvuDqTV8XGZXafX6XH6oa6grF3k%2B%2Bg%2BYU%3D&st=2021-02-08T17%3A59%3A39Z&se=2021-02-09T02%3A09%3A39Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlstorageacc.blob.core.windows.net/azureml/ExperimentRun/dcid.1a5c0f11-a35f-43d3-a657-f478b03d8349/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=qNSTK0nv%2FR3eaAhB3tsppPqKS0cWjGmjoEJv2V8lbOE%3D&st=2021-02-08T17%3A59%3A39Z&se=2021-02-09T02%3A09%3A39Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlstorageacc.blob.core.windows.net/azureml/ExperimentRun/dcid.1a5c0f11-a35f-43d3-a657-f478b03d8349/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=3aJGzf6Yx1TxnrszZuTQ%2Fv8xL%2FEKKlDUZ2ovWiWp7IU%3D&st=2021-02-08T17%3A59%3A39Z&se=2021-02-09T02%3A09%3A39Z&sp=r'}, 'submittedBy': 'Bjarne Meyn'}\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "# Submit the pipeline to be run\n",
    "pipeline_run = Experiment(ws, 'data_ingest').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(Name: Ingest_Pipeline,\n",
       "Id: 36ddcf2f-5e9f-41ba-afd3-423c4b2bba4a,\n",
       "Status: Active,\n",
       "Endpoint: https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/3a0172d3-ec0d-46bb-a88a-ff41a302711a/resourceGroups/Evonik/providers/Microsoft.MachineLearningServices/workspaces/AMLWorkspace/PipelineRuns/PipelineSubmit/36ddcf2f-5e9f-41ba-afd3-423c4b2bba4a)"
      ],
      "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Ingest_Pipeline</td><td><a href=\"https://ml.azure.com/pipelines/36ddcf2f-5e9f-41ba-afd3-423c4b2bba4a?wsid=/subscriptions/3a0172d3-ec0d-46bb-a88a-ff41a302711a/resourcegroups/Evonik/workspaces/AMLWorkspace\" target=\"_blank\" rel=\"noopener\">36ddcf2f-5e9f-41ba-afd3-423c4b2bba4a</a></td><td>Active</td><td><a href=\"https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/3a0172d3-ec0d-46bb-a88a-ff41a302711a/resourceGroups/Evonik/providers/Microsoft.MachineLearningServices/workspaces/AMLWorkspace/PipelineRuns/PipelineSubmit/36ddcf2f-5e9f-41ba-afd3-423c4b2bba4a\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "pipeline_run.publish_pipeline(\n",
    "     name=\"Ingest_Pipeline\",\n",
    "     description=\"Pipeline to create new Dataset with ADF\",\n",
    "     version=\"1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}